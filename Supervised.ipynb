{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step [1]: Prepare libraries and data\n",
    "### [1.1] Include important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "punctuation = punctuation + '\\n'\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "import nltk \n",
    "import string\n",
    "from pyarabic.araby import strip_harakat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_data = pd.read_csv(r\"datasets/arabic_dataset.csv\")\n",
    "ar_data = ar_data.replace(\"diverse\", \"diverse news\")\n",
    "ar_data = ar_data.replace(\"culture\", \"diverse news\")\n",
    "ar_data = ar_data.replace(\"politic\", \"politics\")\n",
    "ar_data = ar_data.replace(\"technology\", \"tech\")\n",
    "ar_data = ar_data.replace(\"economy\", \"economy & business\")\n",
    "ar_data = ar_data.replace(\"internationalNews\", \"politics\")\n",
    "ar_data = ar_data[~ar_data['type'].str.contains('localnews')]\n",
    "ar_data = ar_data[~ar_data['type'].str.contains('society')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4171</th>\n",
       "      <td>1247</td>\n",
       "      <td>\\nيواجه  النادي الصفاقسي عشية اليوم بداية من ا...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>125</td>\n",
       "      <td>\\nوصف رئيس حزب التحالف الديمقراطي، محمد الحامد...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>668</td>\n",
       "      <td>\\nقال مسؤولٌ كبير في إدارة الرئيس الأميركي دون...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>326</td>\n",
       "      <td>\\nيعقد رئيس الترجي الجرجيسي ندوة صحفية في بحر ...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>158</td>\n",
       "      <td>\\nدعا الناطق باسم القيادة العامة للقوات المسلح...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3704</th>\n",
       "      <td>780</td>\n",
       "      <td>\\nدارت اليوم منافسات الجولة الرابعة لمرحلة الت...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>1242</td>\n",
       "      <td>\\nتتواصل الاحتجاجات في الحسيمة المغربية لليوم ...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>643</td>\n",
       "      <td>\\n أهابت تونس، مساء الجمعة، بكل الليبيين، \"الت...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>138</td>\n",
       "      <td>\\nفي حوار حصري أدلى به للجوهرة أف أم، وفي أول ...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>616</td>\n",
       "      <td>\\nأعلن رئيس مجلس النواب، محمد الناصر أمس الجمع...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text      type\n",
       "4171        1247  \\nيواجه  النادي الصفاقسي عشية اليوم بداية من ا...     sport\n",
       "2307         125  \\nوصف رئيس حزب التحالف الديمقراطي، محمد الحامد...  politics\n",
       "1595         668  \\nقال مسؤولٌ كبير في إدارة الرئيس الأميركي دون...  politics\n",
       "3250         326  \\nيعقد رئيس الترجي الجرجيسي ندوة صحفية في بحر ...     sport\n",
       "1085         158  \\nدعا الناطق باسم القيادة العامة للقوات المسلح...  politics\n",
       "3704         780  \\nدارت اليوم منافسات الجولة الرابعة لمرحلة الت...     sport\n",
       "2169        1242  \\nتتواصل الاحتجاجات في الحسيمة المغربية لليوم ...  politics\n",
       "2825         643  \\n أهابت تونس، مساء الجمعة، بكل الليبيين، \"الت...  politics\n",
       "2320         138  \\nفي حوار حصري أدلى به للجوهرة أف أم، وفي أول ...  politics\n",
       "2798         616  \\nأعلن رئيس مجلس النواب، محمد الناصر أمس الجمع...  politics"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def delete_links(input_text):\n",
    "#     pettern  = r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))'''\n",
    "#     out_text = re.sub(pettern, ' ', input_text)\n",
    "#     return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def delete_repeated_characters(input_text):\n",
    "#     pattern  = r'(.)\\1{2,}'\n",
    "#     out_text = re.sub(pattern, r\"\\1\\1\", input_text)\n",
    "#     return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def replace_letters(input_text):\n",
    "#     replace = {\"أ\": \"ا\",\"ة\": \"ه\",\"إ\": \"ا\",\"آ\": \"ا\",\"\": \"\"}\n",
    "#     replace = dict((re.escape(k), v) for k, v in replace.items()) \n",
    "#     pattern = re.compile(\"|\".join(replace.keys()))\n",
    "#     out_text = pattern.sub(lambda m: replace[re.escape(m.group(0))], input_text)\n",
    "#     return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text(input_text):\n",
    "#     replace = r'[/(){}\\[\\]|@âÂ,;\\?\\'\\\"\\*…؟–’،!&\\+-:؛-]'\n",
    "#     out_text = re.sub(replace, \" \", input_text)\n",
    "#     words = nltk.word_tokenize(out_text)\n",
    "#     words = [word for word in words if word.isalpha()]\n",
    "#     out_text = ' '.join(words)\n",
    "#     return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_vowelization(input_text):\n",
    "#     vowelization = re.compile(\"\"\" ّ|َ|ً|ُ|ٌ|ِ|ٍ|ْ|ـ\"\"\", re.VERBOSE)\n",
    "#     out_text = re.sub(vowelization, '', input_text)\n",
    "#     return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def delete_stopwords(input_text):\n",
    "#     stop_words = set(nltk.corpus.stopwords.words(\"arabic\") + nltk.corpus.stopwords.words(\"english\"))\n",
    "#     tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "#     tokens = tokenizer.tokenize(input_text)\n",
    "#     wnl = nltk.WordNetLemmatizer()\n",
    "#     lemmatizedTokens =[wnl.lemmatize(t) for t in tokens]\n",
    "#     out_text = [w for w in lemmatizedTokens if not w in stop_words]\n",
    "#     out_text = ' '.join(out_text)\n",
    "#     return out_text\n",
    "# # print(nltk.corpus.stopwords.words(\"arabic\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def text_prepare(input_text):\n",
    "#     out_text = delete_links(input_text)\n",
    "#     out_text = delete_repeated_characters(out_text)\n",
    "#     out_text = clean_text(out_text)\n",
    "#     out_text = delete_stopwords(out_text)\n",
    "   \n",
    "#     out_text = replace_letters(out_text)\n",
    "#     out_text = remove_vowelization(out_text)\n",
    "    \n",
    "#     return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Cleaning data\n",
    "arabic_punctuations = '''«»`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations\n",
    "\n",
    "def clean(text):\n",
    "    output = re.sub(r'\\s*[A-Za-z]+\\b', ' ' , text) #Remove english letters\n",
    "    output = strip_harakat(output) #Remove harakat   \n",
    "    translator = str.maketrans(' ',' ', punctuations_list) #remove arabic and english punctuations\n",
    "    output = output.translate(translator)\n",
    "    output = \" \".join(output.split()) #remove extra spaces\n",
    "    output = re.sub('\\w*\\d\\w*', ' ', output)# Remove numbers\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning String\n",
    "def apply_clean_string(input_text):\n",
    "    out_text = clean(input_text)\n",
    "    return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>1003</td>\n",
       "      <td>\\nقالت الشرطة الأسترالية يوم الأحد إن طفلا رضي...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>690</td>\n",
       "      <td>\\nعثر عاملون في مطار \"أورلي\" بباريس على جثة رج...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3225</th>\n",
       "      <td>301</td>\n",
       "      <td>\\nاكد نائب رئيس ترجي جرجيس الهاشمي عبيشو في تص...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>68</td>\n",
       "      <td>\\nينتظر فريق النجم الرياضي الساحلي قدوم الحافل...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>329</td>\n",
       "      <td>\\nأصدر قاض اتحادي في هاواي أمرا بوقف تنفيذ الح...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>137</td>\n",
       "      <td>\\nتفاقم العجز التجاري لتونس خلال الأشهر الثلاث...</td>\n",
       "      <td>economy &amp; business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>302</td>\n",
       "      <td>\\nانشغل لص بعد أن تسلّل إلى منزل واقع في ولاية...</td>\n",
       "      <td>diverse news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>863</td>\n",
       "      <td>\\nحذر وزير الأوقاف والشؤون الدينية الفلسطيني ا...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>724</td>\n",
       "      <td>\\nقرر القضاء الفرنسي توجيه اتهامات تتعلق بجرائ...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3364</th>\n",
       "      <td>440</td>\n",
       "      <td>\\nإجتمع اليوم مكتب الرّابطة الوطنيّة  لكرة الق...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               text  \\\n",
       "1930        1003  \\nقالت الشرطة الأسترالية يوم الأحد إن طفلا رضي...   \n",
       "1617         690  \\nعثر عاملون في مطار \"أورلي\" بباريس على جثة رج...   \n",
       "3225         301  \\nاكد نائب رئيس ترجي جرجيس الهاشمي عبيشو في تص...   \n",
       "2992          68  \\nينتظر فريق النجم الرياضي الساحلي قدوم الحافل...   \n",
       "1256         329  \\nأصدر قاض اتحادي في هاواي أمرا بوقف تنفيذ الح...   \n",
       "736          137  \\nتفاقم العجز التجاري لتونس خلال الأشهر الثلاث...   \n",
       "426          302  \\nانشغل لص بعد أن تسلّل إلى منزل واقع في ولاية...   \n",
       "1790         863  \\nحذر وزير الأوقاف والشؤون الدينية الفلسطيني ا...   \n",
       "1651         724  \\nقرر القضاء الفرنسي توجيه اتهامات تتعلق بجرائ...   \n",
       "3364         440  \\nإجتمع اليوم مكتب الرّابطة الوطنيّة  لكرة الق...   \n",
       "\n",
       "                    type  \n",
       "1930            politics  \n",
       "1617            politics  \n",
       "3225               sport  \n",
       "2992               sport  \n",
       "1256            politics  \n",
       "736   economy & business  \n",
       "426         diverse news  \n",
       "1790            politics  \n",
       "1651            politics  \n",
       "3364               sport  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_data['Processed Text'] = ar_data['text'].apply(apply_clean_string)\n",
    "# After label encoding we sholud change some labels to another becouse the arabic dataset labels is not the same with english dataset\n",
    "ar_label_encoder = LabelEncoder()\n",
    "ar_data['Category Encoded'] = ar_label_encoder.fit_transform(ar_data['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Economy & Business', 'Diverse News', 'Politic', 'Sport', 'Technology']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_X_train, ar_X_test, ar_y_train, ar_y_test = train_test_split(ar_data['Processed Text'], ar_data['Category Encoded'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "arb_stopwords = set(nltk.corpus.stopwords.words(\"arabic\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_features(X_train, X_test, ngram_range):\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, ngram_range))\n",
    "    X_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test = tfidf_vectorizer.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_features_train, ar_features_test = tfidf_features(ar_X_train, ar_X_test,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model_name, ar_text=False):\n",
    "    if model_name == 'ridge_model':\n",
    "        model_name = RidgeClassifier()\n",
    "    elif model_name == 'random_forest_model':\n",
    "        model_name = RandomForestClassifier()\n",
    "    elif model_name == 'logistic_regression_model':\n",
    "        model_name = LogisticRegression()\n",
    "    elif model_name == 'kneighbors_model':\n",
    "        model_name = KNeighborsClassifier()\n",
    "    elif model_name == 'decision_tree_model':\n",
    "        model_name = DecisionTreeClassifier()\n",
    "    elif model_name == 'gaussian_nb_model':\n",
    "        model_name = GaussianNB()\n",
    "    if ar_text:\n",
    "        model_name.fit(ar_features_train.toarray(), ar_y_train)\n",
    "        model_predictions = model_name.predict(ar_features_test.toarray())\n",
    "        print(\"Accuracy on test: \", accuracy_score(ar_y_test, model_predictions))\n",
    "   \n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test:  0.9182530795072789\n"
     ]
    }
   ],
   "source": [
    "ar_ridge_model = fit_model('ridge_model', True)\n",
    "pickle.dump(ar_ridge_model, open('models/ar_ridge_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test:  0.8432250839865622\n"
     ]
    }
   ],
   "source": [
    "ar_random_forest_model = fit_model('random_forest_model', True)\n",
    "pickle.dump(ar_random_forest_model, open('models/ar_random_forest_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test:  0.8723404255319149\n"
     ]
    }
   ],
   "source": [
    "ar_logistic_regression_model = fit_model('logistic_regression_model', True)\n",
    "pickle.dump(ar_logistic_regression_model, open('models/ar_logistic_regression_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test:  0.22284434490481522\n"
     ]
    }
   ],
   "source": [
    "ar_kneighbors_model = fit_model('kneighbors_model', True)\n",
    "pickle.dump(ar_kneighbors_model, open('models/ar_kneighbors_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test:  0.7726763717805151\n"
     ]
    }
   ],
   "source": [
    "ar_decision_tree_model = fit_model('decision_tree_model', True)\n",
    "pickle.dump(ar_decision_tree_model, open('models/ar_decision_tree_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test:  0.8622620380739082\n"
     ]
    }
   ],
   "source": [
    "ar_gaussian_nb_model = fit_model('gaussian_nb_model', True)\n",
    "pickle.dump(ar_gaussian_nb_model, open('models/ar_gaussian_nb_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
